{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "# from tensorflow.keras.layers import Dropout, Dense, Bidirectional, LSTM, \\\n",
    "#     Embedding, GaussianNoise, Activation, Flatten, \\\n",
    "#     RepeatVector, GlobalMaxPooling1D, \\\n",
    "#     Convolution1D, MaxPooling1D, concatenate, Conv1D\n",
    "\n",
    "# from tensorflow.keras.layers import Attention\n",
    "# from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@ShaquilleHoNeal from what I think you're aski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>positive</td>\n",
       "      <td>Iran ranks 1st in liver surgeries, Allah bless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Hours before he arrived in Saudi Arabia on Tue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian worth how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20631</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I guess even Pandora knows Justin Bieber is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20632 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity                                              tweet\n",
       "0       neutral  Picturehouse's, Pink Floyd's, 'Roger Waters: T...\n",
       "1       neutral  Order Go Set a Watchman in store or through ou...\n",
       "2      negative  If these runway renovations at the airport pre...\n",
       "3       neutral  If you could ask an onstage interview question...\n",
       "4      positive  A portion of book sales from our Harper Lee/Go...\n",
       "...         ...                                                ...\n",
       "20627   neutral  @ShaquilleHoNeal from what I think you're aski...\n",
       "20628  positive  Iran ranks 1st in liver surgeries, Allah bless...\n",
       "20629   neutral  Hours before he arrived in Saudi Arabia on Tue...\n",
       "20630  negative  @VanityFair  Alex Kim Kardashian worth how to ...\n",
       "20631   neutral  I guess even Pandora knows Justin Bieber is a ...\n",
       "\n",
       "[20632 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"SemEval2017-task4-dev.subtask-A.english.INPUT.txt\",sep=\"\\t\", header=None)\n",
    "df = df.drop(columns=[3])\n",
    "df = df.drop(columns=[0])\n",
    "df.columns = [\"polarity\", \"tweet\"]\n",
    "# df.set_index(\"id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>0</td>\n",
       "      <td>@ShaquilleHoNeal from what I think you're aski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>1</td>\n",
       "      <td>Iran ranks 1st in liver surgeries, Allah bless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>0</td>\n",
       "      <td>Hours before he arrived in Saudi Arabia on Tue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>2</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian worth how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20631</th>\n",
       "      <td>0</td>\n",
       "      <td>I guess even Pandora knows Justin Bieber is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20632 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity                                              tweet\n",
       "0             0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...\n",
       "1             0  Order Go Set a Watchman in store or through ou...\n",
       "2             2  If these runway renovations at the airport pre...\n",
       "3             0  If you could ask an onstage interview question...\n",
       "4             1  A portion of book sales from our Harper Lee/Go...\n",
       "...         ...                                                ...\n",
       "20627         0  @ShaquilleHoNeal from what I think you're aski...\n",
       "20628         1  Iran ranks 1st in liver surgeries, Allah bless...\n",
       "20629         0  Hours before he arrived in Saudi Arabia on Tue...\n",
       "20630         2  @VanityFair  Alex Kim Kardashian worth how to ...\n",
       "20631         0  I guess even Pandora knows Justin Bieber is a ...\n",
       "\n",
       "[20632 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"polarity\"].replace({\"positive\": 1, \"negative\": 2 , \"neutral\": 0}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.pop('polarity')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "        'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22056"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_set = set()\n",
    "for text_tensor, _ in dataset:\n",
    "    text = str(text_tensor.numpy()[0], 'utf-8')\n",
    "    some_tokens = text_processor.pre_process_doc(text)\n",
    "#     print(some_tokens)\n",
    "    vocabulary_set.update(some_tokens)\n",
    "    \n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "  encoded_text = encoder.encode(text_tensor.numpy()[0])\n",
    "  return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode_map_fn(text, label):\n",
    "  # py_func doesn't set the shape of the returned tensors.\n",
    "  encoded_text, label = tf.py_function(encode, \n",
    "                                       inp=[text, label], \n",
    "                                       Tout=(tf.int64, tf.int64))\n",
    "\n",
    "  # `tf.data.Datasets` work best if all components have a shape set\n",
    "  #  so set the shapes manually: \n",
    "  encoded_text.set_shape([None])\n",
    "  label.set_shape([])\n",
    "\n",
    "  return encoded_text, label\n",
    "\n",
    "\n",
    "all_encoded_data = dataset.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "DATASET_SIZE = 20632\n",
    "TEST_SIZE = int(0.15 * DATASET_SIZE)\n",
    "VAL_SIZE = int(0.15 * DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_encoded_data.skip(TEST_SIZE+VAL_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
    "\n",
    "test_val_data = all_encoded_data.take(TEST_SIZE+VAL_SIZE)\n",
    "# test_val_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
    "\n",
    "test_data = test_val_data.skip(VAL_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
    "\n",
    "val_data = test_val_data.take(VAL_SIZE)\n",
    "val_data = val_data.padded_batch(BATCH_SIZE, padded_shapes=([None],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=50801, shape=(29,), dtype=int64, numpy=\n",
       " array([17737, 11504, 15258,  7737, 12862,  7737, 22057,  5027,  2969,\n",
       "         5027, 12724,  7061,  7157,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0], dtype=int64)>,\n",
       " <tf.Tensor: id=50805, shape=(), dtype=int64, numpy=1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text, sample_labels = next(iter(test_data))\n",
    "\n",
    "sample_text[0], sample_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 64))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "# One or more dense layers.\n",
    "# Edit the list in the `for` line to experiment with layer sizes.\n",
    "for units in [64, 64]:\n",
    "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "# Output layer. The first argument is the number of labels.\n",
    "model.add(tf.keras.layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "226/226 [==============================] - 15s 64ms/step - loss: 0.9508 - accuracy: 0.5291 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 0.7258 - accuracy: 0.6737 - val_loss: 0.8365 - val_accuracy: 0.6089\n",
      "Epoch 3/3\n",
      "226/226 [==============================] - 9s 41ms/step - loss: 0.5583 - accuracy: 0.7606 - val_loss: 0.8777 - val_accuracy: 0.6037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bd9898aa08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=3, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 32ms/step - loss: 0.8629 - accuracy: 0.6157\n",
      "\n",
      "Eval loss: 0.863, Eval accuracy: 0.616\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc = model.evaluate(test_data)\n",
    "\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
